---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am Jiawang Liu, a Ph.D. candidate at the College of Information Science and Electronic Engineering, Zhejiang University (2022â€“present), under the supervision of Prof. [Lu Yu](https://person.zju.edu.cn/yul). I received my B.Eng. in Information Engineering from Jilin University.

<!-- My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# ğŸ”¥ News
<!-- - *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# ğŸ“ Publications 

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div> -->


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ISCAS 2025</div><img src='images/ISCAS_2025_v2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Assessing the Reusability of Cloud-Received Feature Streams on Advanced Networks](https://ieeexplore.ieee.org/document/11044016/) [poster]

**Jiawang Liu**, Ao Liu, Hualong Yu, Heming Sun,Lu Yu

IEEE ISCAS, 2025

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ISCAS 2025</div><img src='images/ISCAS_2025_v1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Learning-based Image Coding for Machine Intelligence with Variable-Rate](https://ieeexplore.ieee.org/document/11043320/) [**oral**]

Ao Liu, Hualong Yu, **Jiawang Liu**, Qiqi He, Lu Yu

IEEE ISCAS, 2025

</div>
</div>



<div class='paper-box' id="VCIP_2023"><div class='paper-box-image'><div><div class="badge">VCIP 2023</div><img src='images/VCIP_2023.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Evaluation on the generalization of coded features across neural networks of different tasks](https://ieeexplore.ieee.org/document/10402702/) [**oral**]

**Jiawang Liu**, Ao Liu, Ke Jia, Hualong Yu, Lu Yu

IEEE VCIP, 2023 \| Relevant work has been adopted by <a href="#VCIP_2023_DCM">DCM</a>.

</div>
</div>



# ğŸ“„ Proposals

## ğŸ“‹ Summary

* Chinese National Standard (DCM): **13** proposals submitted (<span style="color:red;">12</span> as first author, <span style="color:red;">3</span> adopted, <span style="color:red;">1</span> collaborative work adopted)
* International Standards (VCM, FCM): **15** proposals submitted (<span style="color:red;">6</span> as first author, <span style="color:red;">1</span> adopted by FCM)

<!-- ---- -->

## <img src="images/esi.jpg" width="20"> Data Coding for Machine (DCM)
---


### âœ… Adopted Proposals

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">DCM 2025</div><img src='images/Infrared_visualization.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="color: #224B8D;">EE3ï¼šDCMåœ¨äºŒç»´å¯è§å…‰çº¢å¤–è§†é¢‘æ•°æ®é›†ä¸Šçš„å‹ç¼©æ€§èƒ½æ¢ç©¶</span>

**åˆ˜ä½³æ—º**ã€äºåŒ–é¾™ã€è™éœ²ï¼ˆæµ™æ±Ÿå¤§å­¦ï¼‰ã€æ—æ™“ä¸œï¼ˆèŠ¯ç¦ç§‘æŠ€ï¼‰

DCM-I-0170, DCMç¬¬19æ¬¡ä¼šè®®ï¼Œ2025å¹´7æœˆ

**Pre- and Post-processing Modules Adapted for Thermal Images** have been adopted.

[Project Page]()
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">DCM 2025</div><img src='images/overall.drawio.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="color: #224B8D;">DCMå®šç‚¹åŒ–ç®—æ³•æ”¹è¿›åŠç›¸åº”æ ‡å‡†æ–‡æœ¬ä¿®æ”¹å»ºè®®</span>

**åˆ˜ä½³æ—º**ã€äºåŒ–é¾™ã€è™éœ²

DCM-I-162, DCMç¬¬18æ¬¡ä¼šè®®ï¼Œ2025å¹´4æœˆ

**Fixed-point Algorithm** has been adopted.

</div>
</div>


<div class='paper-box' id="VCIP_2023_DCM"><div class='paper-box-image'><div><div class="badge">DCM 2023</div><img src='images/decoupled_context.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="color: #224B8D;">è§£æè§£ç åˆ†ç¦»çš„é«˜æ•ˆå›¾åƒç¼–ç æ–¹æ³•</span>

ä½•æ·‡æ·‡ã€**åˆ˜ä½³æ—º**ã€äºåŒ–é¾™ã€è™éœ²

DCM-I-0116ï¼Œ DCMç¬¬13æ¬¡ä¼šè®®ï¼Œ2023å¹´11æœˆ

**Decoupled Context Model** has been adopted.

</div>
</div>


<div class='paper-box' id="VCIP_2023_DCM"><div class='paper-box-image'><div><div class="badge">DCM 2023</div><img src='images/VCIP_2023.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="color: #224B8D;">DTM-V CE2ï¼šéªŒè¯è§£ç ç‰¹å¾çš„é€šç”¨æ€§</span>

**åˆ˜ä½³æ—º**ã€äºåŒ–é¾™ã€è™éœ²

DCM-I-0077,  DCMç¬¬10æ¬¡ä¼šè®®ï¼Œ2023å¹´2æœˆ

**Feature Adapter** has been adopted. \| Relevant work has been accepted by <a href="#VCIP_2023">VCIP 2023</a>.

</div>
</div>




### ğŸ“ Other Selected Proposals

<!-- <div class="scroll-list-container"> -->

* **åˆ˜ä½³æ—º**ã€äºåŒ–é¾™ã€è™éœ², â€œDTM-V CE2è¡¥å……å®éªŒï¼šéªŒè¯è§£ç ç‰¹å¾åœ¨å®ä¾‹åˆ†å‰²ä»»åŠ¡ä¸Šçš„æ³›åŒ–æ€§â€ï¼ŒDCM-I-0086ï¼Œ DCMç¬¬11æ¬¡ä¼šè®®ï¼Œ2023å¹´5æœˆã€‚
* **åˆ˜ä½³æ—º**ã€äºåŒ–é¾™ã€è™éœ², â€œDCM-I-147-DTMç‰¹å¾åœ¨åŸºäºTrasnformerçš„ç›®æ ‡æ£€æµ‹ç½‘ç»œä¸Šçš„æ³›åŒ–æ€§éªŒè¯â€, DCM-I-147, DCMç¬¬16æ¬¡ä¼šè®®ï¼Œ2024å¹´9æœˆã€‚
* **åˆ˜ä½³æ—º**ã€äºåŒ–é¾™ã€è™éœ², â€œDCM-I-163-DCMå‚è€ƒè½¯ä»¶åœ¨å¼€å‘æ¿ä¸Šçš„éƒ¨ç½²å±•ç¤ºâ€, DCM-I-163, DCMç¬¬18æ¬¡ä¼šè®®ï¼Œ2025å¹´4æœˆã€‚
* **åˆ˜ä½³æ—º**ï¼Œâ€œDCM-O-0089-TSUCA 024.2ã€Šä¿¡æ¯æŠ€æœ¯é¢å‘æœºå™¨æ™ºèƒ½å›¾åƒç¼–ç ç¬¬2ç‰ˆï¼šè‰æ¡ˆã€‹å›¢æ ‡ä¿®è®¢ç‰ˆè‰æ¡ˆâ€ï¼ŒDCM-O-0089, DCMç¬¬18æ¬¡ä¼šè®®ï¼Œ2025å¹´4æœˆã€‚

<!-- </div> -->



## <img src="images/mpeg.drawio.png" width="80"> MPEG-Video/Feature Coding for Machine (VCM/FCM)
---

### âœ… Adopted Proposals
<div class='paper-box' id="VCIP_2023_DCM"><div class='paper-box-image'><div><div class="badge">FCM 2024</div><img src='images/symmetrioc_flipping.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="color: #224B8D;">Jiawang Liu, Ao Liu, Chao Wang, Hualong Yu, Lu Yu (Zhejiang University)], "[FCVCM] Feature Coding scheme for Video Coding for Machine from Zhejiang University", ISO/IEC JTC 1/SC 29/WG2  m65221, Hannover, October, 2023.</span>

**Jiawang Liu**, Ao Liu, Chao Wang, Hualong Yu, Lu Yu

**Symmetric Feature Channel Flipping** has been adopted by FCM (FCTM V2) in 2024.

(I originally proposed the technique, while the relevant CE was done by my classmates.)

</div>
</div>


### ğŸ“ Other Selected Proposals
<!-- <div class="scroll-list-container"> -->

* **Jiawang Liu**, Hualong Yu, Lu Yu (ZJU), "[FCM] Suggestions on keeping alignment between FCM requirements and FCM CTTC", ISO/IEC JTC 1/SC 29/WG4  m66509, OnLine, January 2024.
* **Jiawang Liu**, Ao Liu, Kejia, Hualong Yu, Lu Yu (Zhejiang University), "[FCVCM] Analysis on Feature Generalization for Multi-tasks", ISO/IEC JTC 1/SC 29/WG2  m65225, Hannover, October, 2023.
* **Jiawang Liu**, Ao Liu, Chao Wang, Hualong Yu, Lu Yu (Zhejiang University)], "[FCVCM] Feature Coding scheme for Video Coding for Machine from Zhejiang University", ISO/IEC JTC 1/SC 29/WG2  m65221, Hannover, October, 2023.
* **Jiawang Liu**, Ao Liu, [Hualong Yu](mailto:hlyu@zju.edu.cn), Lu Yu, "[VCM] Dealing with non-monotonic distributed R-D points",  ISO/IEC JTC 1/SC 29/WG4 m64389, Geneva, July 2023.

<!-- </div> -->

# Projects

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">DCM 2025</div><img src='images/system_deploy2.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<span style="color: #224B8D;">Distributed System Deployment of Machine-Intelligence-Oriented Codecs</span>

**Jiawang Liu**, Ao Liu, Hualong Yu, Lu Yu


[Project Page]()

</div>
</div>


<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

# ğŸ– Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ“– Educations
- *2022.09 - now*, Ph.D. in Information and Communication Engineering, College of Information Science and Electronic Engineering, <img src="images/zju_logo.png" width="60"> Zhejiang University.
- *2018.09 - 2022.06*, B.Eng. in Information Engineering, <img src="images/jlu_logo.jpg" width="35"> Jilin University.


<!-- # ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

<!-- # ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->