---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am Jiawang Liu, a Ph.D. candidate at the College of Information Science and Electronic Engineering, Zhejiang University (2022â€“present), under the supervision of Prof. Lu Yu. I received my B.Eng. in Information Engineering from Jilin University.

<!-- My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# ğŸ”¥ News
<!-- - *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# ğŸ“ Publications 

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div> -->


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ISCAS 2025</div><img src='images/ISCAS_2025_v2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Assessing the Reusability of Cloud-Received Feature Streams on Advanced Networks](https://ieeexplore.ieee.org/document/11044016/) [poster]

**Jiawang Liu**, Ao Liu, Hualong Yu, Heming Sun,Lu Yu

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ISCAS 2025</div><img src='images/ISCAS_2025_v1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Learning-based Image Coding for Machine Intelligence with Variable-Rate](https://ieeexplore.ieee.org/document/11043320/) [oral]

Ao Liu, Hualong Yu, **Jiawang Liu**, Qiqi He, Lu Yu

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">VCIP 2023</div><img src='images/VCIP_2023.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Evaluation on the generalization of coded features across neural networks of different tasks](https://ieeexplore.ieee.org/document/10402702/) [oral]

**Jiawang Liu**, Ao Liu, Ke Jia, Hualong Yu, Lu Yu

</div>
</div>



# ğŸ“„ Proposals

## Summary

* Chinese National Standard (DCM): 13 proposals submitted (12 as first author, 4 adopted, 1 collaborative work adopted)
* International Standards (VCM, FCM): 15 proposals submitted (6 as first author, 1 collaborative work adopted by FCM)

<!-- ---- -->

## Data Coding for Machine (DCM)
<!-- --- -->


### Adopted Proposals

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">DCM 2025</div><img src='images/' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

åˆ˜ä½³æ—ºã€äºåŒ–é¾™ã€è™éœ²ï¼Œâ€œDCM-I-0170-EE3ï¼šDCMåœ¨äºŒç»´å¯è§å…‰çº¢å¤–è§†é¢‘æ•°æ®é›†ä¸Šçš„å‹ç¼©æ€§èƒ½æ¢ç©¶â€ï¼ŒDCM-I-0170, DCMç¬¬19æ¬¡ä¼šè®®ï¼Œ2025å¹´7æœˆã€‚

**Jiawang Liu**, HualongYu, Lu Yu
[Project Page]()

</div>
</div>


### Other Selected Proposals

<div style="height: 260px; overflow-y: auto; border: 1px solid #ddd; padding: 10px;">

1.  é¡¹ç›®ä¸€
2.  é¡¹ç›®äºŒ
3.  é¡¹ç›®ä¸‰
4.  é¡¹ç›®å››
5.  é¡¹ç›®äº”
6.  é¡¹ç›®å…­
7.  é¡¹ç›®ä¸ƒ
8.  é¡¹ç›®å…«
9.  é¡¹ç›®ä¹
10. é¡¹ç›®å
11. é¡¹ç›®åä¸€ï¼ˆå¼€å§‹æ»šåŠ¨ï¼‰
12. é¡¹ç›®åäºŒ
13. é¡¹ç›®åä¸‰
14. é¡¹ç›®åå››
15. é¡¹ç›®åäº”

</div>

## Mpeg-Video/Feature Coding for Machine (VCM/FCM)
---

### Adopted Proposals

### Other Selected Proposals




<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

# ğŸ– Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ“– Educations
- *2022.09 - now*, Ph.D. in Information and Communication Engineering, College of Information Science and Electronic Engineering, Zhejiang University.
- *2018.09 - 2022.06*, B.Eng. in Information Engineering, Jilin University.


<!-- # ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

<!-- # ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->